{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example 2 -- CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madeira-International-Workshop-in-ML/2022_day_5/blob/main/Notebooks/Example%202%20--%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je1Hjo7jEOX7"
      },
      "source": [
        "# Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKroQ2bU9xJr"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMnv8hDn9zvj",
        "outputId": "e9d4054a-c3fa-426b-ab10-f3b56f05884d"
      },
      "source": [
        "# The following is just to check if the GPU from COLAB can is AVAILABLE\n",
        "is_gpu_available = tf.config.list_physical_devices('GPU')\n",
        "print('GPU is', 'AVAILABLE' if is_gpu_available else 'NOT AVAILABLE')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is AVAILABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2sTX0OK3VJW"
      },
      "source": [
        "# Prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm6NXZrks6Jb"
      },
      "source": [
        "The MNIST database contains 60,000 training images and 10,000 testing images of handwritten digits. \n",
        "\n",
        "Each image in the MNIST dataset is a 28x28 grayscale image containing a digit from 0 to 9, and a label identifying which digit is in the image.\n",
        "![MNIST sample](https://github.com/khanhlvg/DigitClassifier/raw/master/images/mnist.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McFaQ9NA3b9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b5b9c3-b6ca-42f9-fd0c-898d1464ac0b"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist  # The Fashion MNIST data is available directly in the tf.keras datasets API. On the\n",
        "# first execution, the data will be downloaded. Note that then the data is cached\n",
        "\n",
        "(x_train, y_train), (\n",
        "        x_test, y_test) = mnist.load_data()  # Loads the MNIST dataset and returns the training and testing\n",
        "# datasets. Note that we are going to use the training dataset\n",
        "# for training the network, whereas the test dataset (which\n",
        "# contains examples that were employed for training the network)\n",
        "# will be used to assess the generalization capabilities of the\n",
        "# network\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Let's normalize the dataset (both training and testing datasets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv-rvqhARE1o"
      },
      "source": [
        "# Add a color dimension to the images in \"train\" and \"validate\" dataset to\n",
        "# leverage Keras's data augmentation utilities later.\n",
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf4kw611oowI"
      },
      "source": [
        "# Convert data to tf.float32\n",
        "x_train = tf.dtypes.cast(x_train, tf.float32)\n",
        "y_train = tf.dtypes.cast(y_train, tf.float32)\n",
        "x_test = tf.dtypes.cast(x_test, tf.float32)\n",
        "y_test = tf.dtypes.cast(y_test, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMlA9nkGRUPy"
      },
      "source": [
        "# Define data augmentation\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.25,\n",
        "        height_shift_range=0.25,\n",
        "        shear_range=0.25,\n",
        "        zoom_range=0.2\n",
        ")\n",
        "\n",
        "# Generate augmented data from MNIST dataset\n",
        "train_generator = data_generator.flow(x_train, y_train)\n",
        "test_generator = data_generator.flow(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyh424YulP9S"
      },
      "source": [
        "# Create the TensorFlow model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqxDdZnZtQvc"
      },
      "source": [
        "We are going to use a simple convolutional neural network, which is a common technique in computer vision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xBYgw2x-OQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbeb1c8c-aca1-46fc-c8e7-d95f32db3d43"
      },
      "source": [
        "# The following is to create the model\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),  # turns the input into a 1 dimensional set\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')  # output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Check to see if the model is what we pretend\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m8UeJ4qDc3w"
      },
      "source": [
        "# This is just for avoiding overfitting\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            logs = {}\n",
        "        if logs.get('accuracy') > 0.90:\n",
        "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgqZ9xQMDlqn"
      },
      "source": [
        "# Fit and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N4qzk0LgWy1",
        "outputId": "724169d1-ec68-4545-c359-c88e2893e328"
      },
      "source": [
        "# Let's train the model\n",
        "callbacks = MyCallback()\n",
        "model.fit(train_generator, epochs=10, validation_data=test_generator, callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 66s 20ms/step - loss: 0.6662 - accuracy: 0.7821 - val_loss: 0.3312 - val_accuracy: 0.8935\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2832 - accuracy: 0.9112 - val_loss: 0.2296 - val_accuracy: 0.9261\n",
            "\n",
            "Reached 90% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb5e970e250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhfQe2EHtkXb"
      },
      "source": [
        "**Remember:** we are testing the model on images that the model has never seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7kJjVFnB0F1",
        "outputId": "501d76e8-24b7-4abc-af21-e2ac60a1180e"
      },
      "source": [
        "# Evaluate the loss and accuracy from the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Loss {test_loss:.2f} and Accuracy {test_acc * 100:.2f}% on test dataset.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0797 - accuracy: 0.9744\n",
            "Loss 0.08 and Accuracy 97.44% on test dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4V6OimJV2LP",
        "outputId": "ef384ebf-56e4-4e62-dba3-b2545cd34750"
      },
      "source": [
        "# Evaluate the loss and accuracy from the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Loss {test_loss:.2f} and Accuracy {test_acc * 100:.2f}% on test dataset.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2370 - accuracy: 0.9259\n",
            "Loss 0.24 and Accuracy 92.59% on test dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJo6DXyIl_Z2"
      },
      "source": [
        "# Export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDMJsxJrt4lR"
      },
      "source": [
        "Now as we have trained the digit classifier model, we will convert it to TensorFlow Lite format for mobile deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzmTpDDAuNqo",
        "outputId": "a2cb7218-ede8-44d2-cce8-976cdaf0c3df"
      },
      "source": [
        "# Export the SavedModel\n",
        "export_dir = '/tmp/saved_model/1'\n",
        "tf.saved_model.save(model, export_dir=export_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri0bVhaIuOtF"
      },
      "source": [
        "## Perform post-training quantization\n",
        "\n",
        "---\n",
        "\n",
        "### Dynamic range quantization\n",
        "\n",
        "The simplest form of post-training quantization statically quantizes **only the weights** from floating point to integer, which has 8-bits of precision.\n",
        "\n",
        "\n",
        "### Full integer quantization\n",
        "\n",
        "Makes sure that all model math is integer quantized. However, it uses float operators when they don't have an integer implementation.\n",
        "\n",
        "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (around ~100-500 samples) of the **training or validation** data. \n",
        "\n",
        "\n",
        "### Integer only\n",
        "\n",
        "Ensure compatibility with integer only devices (such as 8-bit microcontrollers) and accelerators (such as the Coral Edge TPU) by enforcing full-integer quantization for all ops including the input and output.\n",
        "\n",
        "**The converter will throw an error if it encounters an operation it cannot currently quantize.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk6eC3uIeNWF",
        "outputId": "27552fe3-de10-40e0-a73f-51b1a8ad582c"
      },
      "source": [
        "type_quantization = 'Dynamic'  #@param [\"none\", \"Dynamic\", \"Full\", \"Integer only\"]\n",
        "\n",
        "\n",
        "# For post-training quantization, let's define a representative dataset to calibrate variable tensors (e.g., model\n",
        "# input, activations (outputs of intermediate layers). This dataset can be a small subset (around ~100--500 samples) of \n",
        "# the training or validation data\n",
        "def representative_dataset():\n",
        "    for _ in range(100):\n",
        "        data = x_train[:100]\n",
        "        yield [tf.dtypes.cast(data, tf.float32)]\n",
        "\n",
        "\n",
        "# Prepare the converter with post-training quantization\n",
        "if type_quantization == 'none':\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "    tflite_model = converter.convert()\n",
        "elif type_quantization == 'Dynamic':\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    tflite_model = converter.convert()\n",
        "elif type_quantization == 'Full':\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = representative_dataset\n",
        "    tflite_model = converter.convert()\n",
        "elif type_quantization == 'Integer only':\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = representative_dataset\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "# Prepare path string\n",
        "model_path = 'mnist.tflite'\n",
        "\n",
        "# Save the model\n",
        "tflite_model_file = pathlib.Path(model_path)\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "251120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGoGVgOBoZyX"
      },
      "source": [
        "# TensorFlow Lite Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poq-I8Wso22L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c5e54e-038d-4b81-a1c4-b494f3e363f4"
      },
      "source": [
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "# No. examples for testing\n",
        "no_test = 2000  #@param {type:\"integer\"}\n",
        "\n",
        "# Foreach testing sample\n",
        "for i in tqdm(range(no_test)):\n",
        "\n",
        "    # Extract the input\n",
        "    if type_quantization == 'Integer only':\n",
        "        img = np.expand_dims(x_test[i], axis=0).astype(np.int8)\n",
        "    else:\n",
        "        img = np.expand_dims(x_test[i], axis=0)\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "\n",
        "    # Run the model\n",
        "    interpreter.invoke()\n",
        "    digit = np.argmax(interpreter.get_tensor(output_index)[0])\n",
        "\n",
        "    # Collect the result\n",
        "    predictions.append(digit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:32<00:00, 62.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPiZkkS_4ISj",
        "outputId": "956069f7-0f96-4a60-9a5f-89afacccc4f2"
      },
      "source": [
        "results = pd.DataFrame({'Real': y_test[:no_test], 'Predicted': predictions})\n",
        "results['OK'] = results.Real == results.Predicted\n",
        "\n",
        "print(f'Test accuracy {(np.sum(results[\"OK\"] == True) / no_test) * 100.0:.5f}%.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 96.70000%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCBcBsxss3LK"
      },
      "source": [
        "## Download the model for using on Android devices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8QGkqCkssHJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "20116698-9f73-403a-94d1-b9fae3088041"
      },
      "source": [
        "files.download(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c0fcd34d-0d36-4976-9ea9-963f2a664f8c\", \"mnist.tflite\", 251120)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}